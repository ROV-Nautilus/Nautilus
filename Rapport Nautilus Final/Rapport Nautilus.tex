\documentclass[a4paper,11pt]{report}
 
% Import des extensions
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}
\usepackage{graphicx}
\usepackage{color}
\usepackage[table]{xcolor}
\usepackage{colortbl}
\usepackage{geometry}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{fullpage}
\usepackage{listings}
\usepackage{lipsum}
\usepackage{eso-pic}
\usepackage[nottoc]{tocbibind}
\geometry{hmargin=2.5cm,vmargin=3.5cm}

\definecolor{darkWhite}{rgb}{0.94,0.94,0.94}

\lstset{
  aboveskip=3mm,
  belowskip=-2mm,
  backgroundcolor=\color{darkWhite},
  basicstyle=\footnotesize,
  breakatwhitespace=false,
  breaklines=true,
  captionpos=b,
  commentstyle=\color{red},
  deletekeywords={...},
  escapeinside={\%*}{*)},
  extendedchars=true,
  framexleftmargin=16pt,
  framextopmargin=3pt,
  framexbottommargin=6pt,
  frame=tb,
  keepspaces=true,
  keywordstyle=\color{purple},
  literate=
  {²}{{\textsuperscript{2}}}1
  {⁴}{{\textsuperscript{4}}}1
  {⁶}{{\textsuperscript{6}}}1
  {⁸}{{\textsuperscript{8}}}1
  {€}{{\euro{}}}1
  {é}{{\'e}}1
  {è}{{\`{e}}}1
  {ê}{{\^{e}}}1
  {ë}{{\¨{e}}}1
  {É}{{\'{E}}}1
  {Ê}{{\^{E}}}1
  {û}{{\^{u}}}1
  {ù}{{\`{u}}}1
  {â}{{\^{a}}}1
  {à}{{\`{a}}}1
  {á}{{\'{a}}}1
  {ã}{{\~{a}}}1
  {Á}{{\'{A}}}1
  {Â}{{\^{A}}}1
  {Ã}{{\~{A}}}1
  {ç}{{\c{c}}}1
  {Ç}{{\c{C}}}1
  {õ}{{\~{o}}}1
  {ó}{{\'{o}}}1
  {ô}{{\^{o}}}1
  {Õ}{{\~{O}}}1
  {Ó}{{\'{O}}}1
  {Ô}{{\^{O}}}1
  {î}{{\^{i}}}1
  {Î}{{\^{I}}}1
  {í}{{\'{i}}}1
  {Í}{{\~{Í}}}1,
  morekeywords={*,...},
  numbers=left,
  numbersep=10pt,
  numberstyle=\tiny\color{black},
  rulecolor=\color{black},
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  stepnumber=1,
  stringstyle=\color{gray},
  tabsize=4,
  title=\lstname,
}

\newcommand{\blap}[1]{\vbox to 0pt{#1\vss}}
\newcommand\AtUpperLeftCorner[3]{%
\put(\LenToUnit{#1},\LenToUnit{\dimexpr\paperheight-#2}){\blap{#3}}%
}
\newcommand\AtTopCenterPage[2]{%
\put(\LenToUnit{.5\paperwidth},\LenToUnit{\dimexpr\paperheight-#1}){\blap{\hbox to 0pt{\hss#2\hss}}}%
}
\newcommand\AtUpperRightCorner[3]{%
\put(\LenToUnit{\dimexpr\paperwidth-#1},\LenToUnit{\dimexpr\paperheight-#2}){\blap{\llap{#3}}}%
}


\author{Dylan Bideau, Julien Turpin, Pierre Bogrand, Guillaume Vincenti}
\title{\huge{Nautilus - Rapport}}
\date{21 Avril 2018}

\begin{document}
\makeatletter
\begin{titlepage}

	\AddToShipoutPicture{
		\AtUpperLeftCorner{1.5cm}{1cm}{\includegraphics[width=4cm]{Photos/ensea2}}
	}
	\AddToShipoutPicture{
		\AtUpperRightCorner{1.5cm}{1cm}{\includegraphics[width=5cm]{Photos/nautilus}}
	}
	
	
	\begin{center}
		\vspace*{10cm}
		\textsc{\@title}
		\vspace*{0.5cm}
		\hrule
		\vspace*{0.5cm}
		\large{\@author}
	\end{center}
	\vspace*{9.2cm}
	\begin{center}
		\large{\@date}
	\end{center}
\end{titlepage}
\ClearShipoutPicture

\renewcommand{\contentsname}{Sommaire}
\tableofcontents


\chapter{Introduction}

        Les fonds marins réunissent aujourd'hui de nombreux secteurs et enjeux, tant professionnels que particuliers. On y retrouve entre autre l'exploration sous-marine, la surveillance et maintenance d'installations professionnelles, ainsi que la cartographie des fonds marins. Tout ces domaines demandent le développement de solutions techniques plus rentables et pratiques qu'une intervention humaine. Notre projet propose ainsi un ROV (Remotely Operated Vehicle) polyvalent et simple d'utilisation à cet effet.

\chapter{Présentation du projet}
        
				Un ROV est un robot sous-marin contrôlé à distance et permettant une acquisition d'informations, visuelles ou à partir de capteurs. Notre projet de ROV filoguidé, Nautilus, sera transportable et pilotable à l'aide d'un ordinateur portable. Il permettra d'observer facilement des installations ou des fonds marins à l'aide de caméras. Disposant également de fonctions avancées, le Nautilus sera en mesure de recréer le fond marin d'une zone géographique déterminée par l'utilisateur à partir d'une batterie de photographies prises lors de la phase d'exploration. Les différentes fonctionnalités du Nautilus en font ainsi un outil polyvalent, permettant exploration, maintenance et cartographie des fonds.
				
				
\chapter{Cahier des charges}

        \section{Analyse Fonctionnelle}
						\subsection{Structure}
								Facilement transportable et peu encombrant.\newline
								\textbf{Contraintes :}
								\begin{itemize}
										\item Poids : 2-3kg
										\item Dimension : 300*200*150mm
										\item Étanche de norme IP 68 \newline \newline
									\end{itemize}

						\subsection{Commandabilité}
								Commandé à distance par une liaison filaire.\newline
								\textbf{Contraintes :}
								\begin{itemize}
										\item Câble : 15m
										\item Carte intégrée dans le ROV
										\item FPV (First Person View)
										\item Piloté au clavier\newline \newline
								\end{itemize}

						\subsection{Milieu d'utilisation}
								Adapté aux contraintes imposées par son environnement. \newline
								\textbf{Contraintes :}
								\begin{itemize}
										\item Eau non salé (moins de 1 g de sels dissous par kilogramme d'eau)
										\item Eau translucide (transmittance de la lumière entre 75\% et 95\%)
										\item Lieu : Piscine, lac
										\item Écoulement laminaire
										\item Courant marin inférieur à 2 nœuds
										\item Profondeur de 10m (résistant à 2 bars) \newline \newline
								\end{itemize}

						\subsection{Énergie}
								Être entièrement autonome. \newline
								\textbf{Contraintes :}
								\begin{itemize}
										\item Autonomie de 20 minutes
								\end{itemize}

						\subsection{Motorisation}
								Être mobile une fois immergé. \newline
								\textbf{Contraintes :}
								\begin{itemize}
										\item Propulsion électrique
										\item Déplacement horizontal (Vitesse maximale de 1m/s)
										\item Déplacement vertical (Vitesse maximale de 0.5m/s)
										\item Direction droite/gauche à 360 degrés   \newline \newline
								\end{itemize}

						\subsection{Acquisitions}
								Acquérir et transmettre l'information. \newline
								\textbf{Contraintes :}
								\begin{itemize}
										\item Acquisition et retransmission d'un signal vidéo
										\item Acquisition et stockage de photographies
										\item Mesure de la pression
										\item Mesure de la position relative avec signaux GPS
								\end{itemize}

\chapter{Outils de gestion}

        \section{Trello}
					Notre premier outil de gestion est Trello. Il nous permet de gérer notre projet en terme de planification des tâches. Nous utilisons un code couleur pour chaque membre du projet :
						\begin{figure}[!h]
							\begin{center}
								\includegraphics[scale=0.5]{Illustrations/Couleur.png}
								\caption{Trello - Code Couleur}
							\end{center}
						\end{figure}
						\newline Voici actuellement ce que nous devons faire (Lors du premier livrable) :
						\begin{figure}[!h]
							\begin{center}
								\includegraphics[scale=0.4]{Illustrations/Planning1.png}
								\caption{Trello - Planning A faire}
							\end{center}
						\end{figure}
						\newpage Et ce que nous sommes entrain de faire ainsi que les tâches terminées :
						\begin{figure}[!h]
							\begin{center}
								\includegraphics[scale=0.5]{Illustrations/Planning2.png}
								\caption{Trello - Planning En cours et Terminé}
							\end{center}
						\end{figure}
						
        \section{Github}
				Tout notre code, que cela soit pour les documents en latex ou les codes liés au projet, est sur Github :
				\url{https://github.com/ROV-Nautilus/Nautilus}
				\newline En voici un aperçu :
					\begin{figure}[!h]
							\begin{center}
								\includegraphics[scale=0.4]{Illustrations/Github.png}
								\caption{Github - Nautilus}
							\end{center}
						\end{figure}
				
				\section{Gestion de Budget}
				La gestion de notre budget est réalisé à l'aide d'Excel et de Trello, en effet Trello nous permet de mettre en commun les propositions de dépenses et avec Excel nous stockons l'ensemble des commandes par fournisseurs \newline \newline Les voici ci-dessous :
					\begin{figure}[!h]
							\begin{center}
								\includegraphics[scale=0.5]{Illustrations/Conrad.png}
								\caption{Commande Conrad}
							\end{center}
					\end{figure}
					\begin{figure}[!h]
							\begin{center}
								\includegraphics[scale=0.5]{Illustrations/Robotshop.png}
								\caption{Commande Robotshop}
							\end{center}
					\end{figure}
					\begin{figure}[!h]
							\begin{center}
								\includegraphics[scale=0.5]{Illustrations/Exptech.png}
								\caption{Commande Exptch}
							\end{center}
					\end{figure}
								
\chapter{Motorisation et énergie}

				\section{Moteurs brushless et ESC} 
				
							Dans un premier temps, il a été question de la technologie des moteurs à utiliser. Après une étude des différentes solutions disponibles, nous avons finalement choisi des moteurs brushless \cite{ref5}. En effet, les moteurs brushless sont des machines synchrones auto-pilotées à aimants permanents et donc sans balais.
			\begin{figure}[!h]
				\begin{center}
					\includegraphics{Photos/moteur-brushless}
					\caption{Moteur Brushless}
				\end{center}
			\end{figure}\newline
							Le principal avantage de ces moteurs est qu'ils peuvent être utilisés immergés dans l'eau sans aucun traitement particulier au préalable. En revanche, un système électronique de commande doit assurer la commutation du courant dans les enroulements statoriques : les ESC, ou Electronic Speed Controllers.
			Un ESC transforme un signal d'alimentation continu, dans notre cas issu d'une batterie, en un signal triphasé envoyé ensuite au moteur brushless. Pour contrôler la vitesse de rotation du moteur, on envoie à l'ESC un signal de commande, généralement créneau, et dont le rapport cyclique définit la vitesse du moteur. 
			\begin{figure}[!h]
				\begin{center}
					\includegraphics[scale=1.8]{Photos/esc}
					\caption{ESC}
				\end{center}
			\end{figure}
			\newpage 
			Les trois ESC utilisés dans un premier temps pour nos moteurs \cite{ref6} sont également équipés d'un circuit éliminateur de batterie, ou BEC, permettant de générer un signal d'alimentation constant de 5V et 3A maximum. Ce dernier permet d'alimenter un autre composant, comme une carte Raspberry Pi dans notre cas, sans avoir à recourir à une seconde batterie. 
			\newline\newline Cependant, ces ESC ne permettent la rotation du moteur que dans un seul sens. Le seul moyen de modifier le sens de rotation du moteur dans ce cas est d'échanger deux des trois signaux déphasés envoyés au moteur. La direction droite/gauche étant assurée par les deux moteurs de propulsion arrière, cette particularité n'est pas problématique: la rotation plus rapide d'un des deux moteurs arrière par rapport à l'autre permet de diriger le ROV à gauche ou à droite. En revanche, le moteur vertical devant assuré la propulsion verticale doit pouvoir tourner dans les deux sens. Un second modèle d'ESC a donc été nécessaire pour permettre au moteur de tourner dans les deux sens. Ce dernier \cite{ref7} possède ainsi un mode "reverse" permettant au moteur de tourner dans les deux sens, ainsi qu'un BEC, et sera donc attribué au moteur vertical du ROV.
	
				\newpage\section{Calibration et commande des ESC}
				
				Traditionnellement, le signal de contrôle envoyé à l'ESC est un signal PWM de fréquence 50 Hz environ, un certain écart de cette valeur étant accepté. Dans notre cas, le signal est généré par une Raspberry Pi 3, et l'amplitude du signal est donc de 3,3 V environ.
				\begin{figure}[!h]
				  \begin{center}
				  	\includegraphics[scale=0.6]{Photos/signal_pwm}
						\caption{Signal PWM}
				  \end{center}
		  	\end{figure}
				\newline\newline La caractéristique la plus importante de ce signal est la largeur de chaque impulsion. C'est cette dernière, généralement entre 0.5 ms et 2.5 ms, qui commande directement l'amplitude du signal envoyé aux moteurs et donc leur vitesse de rotation. Notre carte doit donc être capable de générer un signal créneau à 50 Hz, et de rapport cyclique variable sur commande. Pour générer un tel signal, on utilise le programme \cite{ref8}, disponible sur Github. En effet ce dernier a été conçu pour piloter des servomoteurs à partir des pins GPIO de la Raspberry Pi, et est donc le plus adapté pour générer un tel signal. Pour installer ServoBlaster sur la carte, on rentre les commandes suivantes sur le terminal de Raspbian:
				\begin{figure}[!h]
				  \begin{center}
				  	\includegraphics[scale=1]{Photos/ServoBlaster}
						\caption{Programme Servoblaster}
				  \end{center}
		  	\end{figure}
				
				Une fois cette installation effectuée, on peut générer le signal à l'aide de la commande, toujours dans le terminal de Raspbian, "echo x=y > /dev/servoblaster", où x représente le GPIO que l'on utilise et y la valeur du temps d'état haut, en dizaine de us ( par exemple y=100 correspond à un temps d'état haut de 1 ms). Les valeurs de y peuvent aller de 50 à 250, correspondant respectivement à un temps haut de 0.5 ms et 2.5 ms. \newpage Les valeurs de x désignent les GPIO suivant:
					\begin{figure}[!h]
				  \begin{center}
				  	\includegraphics[scale=1]{Photos/gpio}
						\caption{Valeurs GPIO}
				  \end{center}
		  	\end{figure}
				
				On obtient ainsi des commandes comme ci-dessous:
				
					\begin{figure}[!h]
				  \begin{center}
				  	\includegraphics[scale=1]{Photos/sb}
						\caption{Commandes moteurs}
				  \end{center}
		  	\end{figure}
			
			Avec chaque nouvelle valeur de y modifiant la valeur du temps haut du signal sortant. \newline
			
			Toutefois, avant leur utilisation, les ESC nécessitent d'être calibrés. En effet, en fonction des radiocommandes ou autre dispositifs de commande utilisés, l'intervalle des valeurs du temps d'état haut du signal de commande envoyé à l'ESC peux différer. L'ESC doit donc être calibré pour que la valeur maximale de temps d'état haut corresponde à la vitesse maximale de rotation du moteur. De même pour une valeur neutre (moteur à l'arrêt), et une valeur minimale correspondant à la vitesse de rotation inverse maximale, disponible uniquement pour l'ESC "Reverse"', et donc le moteur vertical associé. \newline
			La calibration ne peut pas être effectuée à l'aide des commandes issues de ServoBlaster, l'ESC nécessitant une variation douce du temps d'état haut pour cela. C'est le cas d'un joystick de télécommande, mais pas du programme ne permettant que des variations abrupts de la valeur du temps d'état haut. La calibration des ESC a donc été effectuée à l'aide d'une radiocommande disponible à l'ENSEA \cite{ref9}. Pour cela, on place le joystick de la manette au point neutre, on branche l'ESC à l'émetteur de la radiocommande et on allume dans l'ordre la radiocommande, puis l'ESC. Lorsque ce dernier s'allume, il associe ainsi automatiquement le signal en train d'être reçu au point neutre, donc moteur immobile. On effectue la même opération avec le joystick au maximum pour calibrer la valeur maximale de temps d'état haut et l'associer à la vitesse maximale de rotation du moteur. Une fois cette calibration effectuée, l'ESC en marche ne fonctionnera qu'après avoir reçu le signal correspondant à l'état neutre pendant un certain temps. Cela permet d'éviter entre autres un démarrage intempestif des moteurs. \newline
			
			Une fois la calibration effectuée, on observe à l'oscilloscope le signal de commande envoyé par la manette pour déterminer le temps d'état haut correspondant au point neutre, à la vitesse maximale, et à la vitesse maximale en rotation inverse pour le moteur vertical.
\newline On obtient les résultats suivants:
			
			\begin{figure}[!h]
				  \begin{center}
				  	\includegraphics[scale=0.8]{Photos/tempsesc}
						\caption{Tableau des temps}
				  \end{center}
		  	\end{figure}
				
				Après calibration et relevé de ces valeurs, on peut bien commander les 3 moteurs à l'aide des commandes de ServoBlaster. \newpage
				
				\section{Alimentation et montage}
				
				On utilise pour l'alimentation des ESC et des moteurs une batterie NiMh, de capacité 3000 mAh et délivrant une tension de 7,2 V \cite{ref10}. L'alimentation de la Raspberry est elle assurée par les BEC des ESC : ces derniers, mis en parallèle, délivrent une alimentation constante d'environ 5V et 3A, suffisante à alimenter la carte. On obtient donc le schéma fonctionnel suivant:
				\begin{figure}[!h]
				  \begin{center}
				  	\includegraphics[scale=0.7]{Photos/archi_rov}
						\caption{Architecture de la motorisation du ROV}
				  \end{center}
		  	\end{figure}
				
				
				Lorsque les 3 moteurs sont à leur vitesse maximale, avec la carte fonctionnelle, le courant prélevé sur la batterie est de 2A maximum. L'autonomie théorique dans cette configuration est donc d'environ 90 minutes. Toutefois cette dernière risque de diminuer avec l'utilisation et donc l'alimentation des différents capteurs, ainsi que la résistance de l'eau en condition.
				
				
\chapter{Acquisition et Commandabilité}
	
	Dans un second temps, nous devons relier les différents éléments de notre ROV sur une carte et ensuite traiter les informations reçu pour pouvoir agir sur les moteurs vus précédemment. Nous avons choisi la Raspberry.
	
	\section{Raspberry}
		Une partie de la programmation et des calculs est effectué sur une Raspberry PI 3 qui supportait tout les types de connections que l'on voulait, en voici la description.
			\begin{figure}[!h]
					\begin{center}
						\includegraphics[scale=0.2]{Photos/Raspberry.jpg}
						\caption{Raspberry}
					\end{center}
				\end{figure}
				
		\subsection{Cameras}
			Nous avons 2 caméras qui permettent, l'une la direction (vision frontale) et l'autre la cartographie (vision par dessous). Dans un premier temps, détaillons leur connexion entre la Raspberry et le traitement effectué par celle-ci.
			
				\subsubsection{Logitech C170}
					La première est une webcam Logitech C170, que nous avons démonté pour l'assemblage, relié en USB à la Raspberry. 
					\begin{figure}[!h]
					\begin{center}
						\includegraphics[scale=0.1]{Photos/Camera11.jpg}
						\caption{Logitech C170}
					\end{center}
				\end{figure}
				\newline Nous l'avons choisi car le pilote de celle ci est deja installé nativement sur la Raspberry. Nous utilisons motion qui permet d'envoyer le flux vidéo venant de la camera et de le diffuser en ligne sur notre adresse local \cite{ref1}. En voici le résultat sur un navigateur:
				\begin{figure}[!h]
					\begin{center}
						\includegraphics[scale=0.4]{Photos/Camera1.png}
						\caption{Photo Caméra Frontale}
					\end{center}
				\end{figure}
				\newline Cette vidéo sera récupérée par l'interface (expliquée dans le chapitre associé) en 640*360.
				
				\subsubsection{Caméra V2}
					La deuxième est un module caméra pour Raspberry \cite{ref2} qui se raccorde directement par une nappe (un bus de type CSI-2). 
					\begin{figure}[!h]
					\begin{center}
						\includegraphics[scale=0.1]{Photos/Camera21.jpg}
						\caption{Module Camera V2 Raspberry}
					\end{center}
				\end{figure}
				\newline Elle se paramètre en python avec les librairies données par le constructeur. De même que l'autre caméra, nous renvoyons un flux vidéo en ligne sur notre adresse local \cite{ref3} mais cette fois-ci sur un autre port.
				\newline
				\newline Le résultat sur un navigateur:
					\begin{figure}[!h]
					\begin{center}
						\includegraphics[scale=0.3]{Photos/Camera2.png}
						\caption{Photo Caméra du dessous}
					\end{center}
				\end{figure}
				\newline La vidéo est diffusée en 1920*1080 et affichée par l'interface.
				\newpage
		
				\subsection{Capteur de Pression/Température}
		Le Nautilus est équipé d'un capteur lui permettent d'obtenir la température et la pression. Pour l'instant le ROV renvoit directement ces données mais il est envisageable d'utiliser par exemple la pression pour déterminer avec precision la profondeur du Nautilus. Le module utilisé pour notre ROV est le MS5803-14BA de Sparkfun \cite{ref11}.
		\newline
		
			\subsubsection{MS5803-14BA}
			\begin{figure}[!h]
					\begin{center}
						\includegraphics[scale=1]{Photos/Capture30.jpg}
						\caption{Capteur de pression et de température MS5803-14BA}
					\end{center}
				\end{figure}
			Ce capteur de pression et de température dispose d'une membrane ,pour des mesures de pressions de gaz ou de liquides, résistant à une pression de 30 Bar. De plus, il possède aussi des interfaces SPI et I2C. Nous utiliserons l'interface I2C car celle-ci utilise moins de connections et la fréquence de communication est basse. De plus bien que les deux modes de communication permettent de placer plusieurs modules sur un même câble, le SPI semble être limité sur la Raspberry. Dans nos conditions de connexion l'adresse esclave est 0x1E. Pour utiliser ce capteur on utilise directement un script python qui sera lancé à chaque fois que l'on veut obtenir la pression. Le script est disponible sur ce site \cite{ref12}.
			Comme ce capteur doit se trouver dans l'eau, nous l'avons recouvert, à l’exception de la membrane de résine Epoxy. \newline
			
				\begin{figure}[!h]
					\begin{center}
						\includegraphics[scale=0.2]{Photos/Capture40.jpeg}
						\caption{Capteur MS5803-14BA avant le coulage dans la résine}
					\end{center}
				\end{figure}
			\newpage
					
		\subsection{Central Inertielle}
		
		Le Nautilus dispose aussi d'une centrale inertielle. Avec celle-ci, le ROV peut déterminer son assiette ainsi que sa vitesse. Il est bien-sûr possible d'extrapoler ces données pour obtenir la position et suivre le déplacement du drone. Le module utilisé pour notre ROV est le MinIMU-9 v2 de Pololu \cite{ref13}.
		
			\subsubsection{MinIMU-9 v2}
			\begin{figure}[!h]
					\begin{center}
						\includegraphics[scale=0.5]{Photos/Capture31.jpg}
						\caption{Matrice inertielle MinIMU-9 v2}
					\end{center}
				\end{figure}
				Cette matrice inertielle se compose d'un gyroscope, d'un accéléromètre et d'un compas. De même ce module dispose des interfaces I2C et SPI mais nous utiliserons une fois encore le I2C. La complexité de la mise en place de cette matrice nous a poussé à aussi utiliser un code trouvé sur internet. Le script est disponible sur ce site \cite{ref14}. Ce code est accompagné d'un tutoriel permettant de mieux le comprendre et le mettre en place. Le code reconnait la matrice inertielle utilisée et donc s'adapte en connaissance, pas besoin de connaître l'adresse esclave. Nous avons quand même réalisé quelques modifications pour obtenir plus facilement les données en continue.En effet nous avons dans un premier temps modifier le fichier "`minimu9-ahrs.cpp"'. Celui-ci ne faisait qu'afficher les valeurs d'angles d’Euler dans le terminal. De plus la vitesse de retour des données était trop rapide, ces même donnée n'étaient pas stockées, et le système ne retournait pas uniquement les angles d’Euler. C'est pour cela que nous avons décidé de stocker les valeurs d'angles d’Euler dans un fichier texte qui se réinitialise toutes les 100 valeurs.
				\newline On remplace alors la ligne d'affichage 63-64 :
				\begin{lstlisting}[language=c++]
void output_euler(quaternion & rotation)
{
  std::cout << (vector)(rotation.toRotationMatrix().eulerAngles(2, 1, 0)
                        * (180 / M_PI));
}
				\end{lstlisting}
				Par le code suivant:
				\begin{lstlisting}[language=c++]

void output_euler(quaternion & rotation)
{
	if (c==100)
	{
		
		std::ofstream fichier("euler.txt", std::ios::out | std::ios::trunc);
		c=0;
		
		if(fichier)
		{
				
			fichier << ((vector)(rotation.toRotationMatrix().eulerAngles(2, 1, 0) * (180 / M_PI)))[0] <<'/'<<((vector)(rotation.toRotationMatrix().eulerAngles(2, 1, 0) * (180 / M_PI)))[1]<<'/'<<((vector)(rotation.toRotationMatrix().eulerAngles(2, 1, 0) * (180 / M_PI)))[2] << std::endl;
			c++;
			fichier.close();
		}
		else
		{
			std::cerr << "Impossible d'ouvrir le fichier !" << std::endl;
		}
	}
	else
	{
		std::ofstream fichier("euler.txt", std::ios::out | std::ios::app);
	
		if(fichier)
			{
				
				fichier << ((vector)(rotation.toRotationMatrix().eulerAngles(2, 1, 0) * (180 / M_PI)))[0] <<'/'<<((vector)(rotation.toRotationMatrix().eulerAngles(2, 1, 0) * (180 / M_PI)))[1]<<'/'<<((vector)(rotation.toRotationMatrix().eulerAngles(2, 1, 0) * (180 / M_PI)))[2] << std::endl;
				c++;
				fichier.close();
			}
			else
			{
				std::cerr << "Impossible d'ouvrir le fichier !" << std::endl;
			}
	}
	std::cout << c;
  
}}
				\end{lstlisting}
				
		On écrit une ligne 'std::cout << c;' pour voir si le compteur de valeurs présent dans le fichier text s'incrémente bien.  
		\newpage
				
		
	\section{PC}
		Maintenant que nous avons relié tous nos moteurs, caméras et capteurs à la Raspberry ainsi qu'un premier traitement des informations, nous allons voir comment nous traitons cela sur le PC.
		
		\subsection{Interface}
			En premier lieu parlons de l'interface, celle ci à pris différentes formes au cours du temps, ici nous présenterons que la dernière version. Toute la partie PC a été programmé en JAVA \cite{ref4}, l'interface utilise la bibliothèque graphique Swing qui nous permet de gérer l'affichage facilement que ce soit pour la vidéo ou pour les interactions.
			Lorsque l'application est lancée, nous arrivons donc dans un premier menu:
			\begin{figure}[!h]
					\begin{center}
						\includegraphics[scale=0.35]{Photos/Interface1.png}
						\caption{Premier Menu Interface}
					\end{center}
				\end{figure}
				\newline Le bouton de Droite mène à une partie que nous développerons dans la partie~\ref{subsec:Cartographie} liée à la Cartographie.
				\newline \newline Nous avons donc crée une fenêtre JFrame:
				\begin{lstlisting}[language=java]
Interface inter = new Interface("Nautilus",0,0,1920,1080,true);
				\end{lstlisting}
				Elle est paramétrée de façon à prendre tous l'écran, ici 1920*1080, les objets se trouvant dans cette fenêtre sont gérés pour se placer en fonction de la taille de l’écran.
				\newline Le manager s'appelle GridBagLayout, il nécessite de paramétrer chaque objet.
				Ce manager crée une grille qui se construit en fonction des paramètres de chaque objet qu'il contient.
				\newpage Prenons exemple du premier bouton FPV:
				\begin{lstlisting}[language=java]
axPanel1.setMinimumSize(new Dimension(400,210));
axPanel1.setMaximumSize(new Dimension(400,210));
axPanel1.setPreferredSize(new Dimension(400,210));
c.fill = GridBagConstraints.BOTH;
c.anchor = GridBagConstraints.CENTER;
c.gridx = 0;
c.gridy = 0;
c.weighty = 0.0;
c.weightx = 0.0;
c.gridwidth = 1;
c.gridheight = 1;
c.insets = new Insets(0, 0, 0, 200);
				\end{lstlisting}
				Les 3 premières lignes correspondent à la taille du bouton, que nous avons choisi ici de garder fixe.
				\newline La ligne 4 n'est pas utile dans ce cas mais permet de correctement redimensionner l'objet lorsque la fenêtre change de taille.
				\newline La ligne 5 fixe l'objet au centre de la partie qui lui a été alloué.
				\newline La ligne 6 et 7 donne la ligne et la colonne où doit se situer l'objet.
				\newline La ligne 8 et 9 définissent des poids en x et y qui sont utilisé lors d'un redimensionnement, cela permet de donner plus de poids à un objet plutôt qu'à un autre. Nous ne l'utilisons pas d'où la valeur 0.
				\newline La ligne 10 et 11 permettent de définir combien de ligne et combien de colonne va prendre notre objet.
				\newline La ligne 12 insère une marge dans l'ordre suivant (margeSupérieure, margeGauche, margeInférieur, margeDroite).
				\newline Chaque objet de notre interface est défini de cette façon.
				\newline Ensuite il y a le bouton de Gauche qui lance le système complet. Un nouveau menu remplace le précédent:
				\begin{figure}[!h]
					\begin{center}
						\includegraphics[scale=0.15]{Photos/Interface2.png}
						\caption{Photo Deuxième menu interface}
					\end{center}
				\end{figure}
				\newline Nous avons maintenant la FPV en haut à gauche, le bouton à droite est le même précédemment, les informations des capteurs sont affichées à droite, les commandes envoyées aux moteurs sont en bas et pour finir un affichage 3D (\ref{subsec:Affichage 3D}) avec JAVA3D en bas à droite. Toutes les informations étant actualisées en temps réel avec la Raspberry. Nous allons voir comment.
				
		\subsection{Tunnel SSH}
			Nous avons choisi d'échanger les données avec la Raspberry par SSH, pour cela on utilise la bibliothèque Jcraft, plus précisément jsch. Au lancement de l'application, il y a 5 tunnels qui se créent (1 pour chaque caméras, 1 pour chaque capteurs et 1 pour les moteurs), ils sont crées au tout début pour ensuite permettre de transmettre directement les données sans refaire la procédure de connexion, le système gagne en rapidité. 
			\newline Détaillons maintenant la procédure qui permet de crée ses tunnels. Comme nous sommes en JAVA, une seule classe permet de crée un tunnel et cette classe est ensuite instanciée autant de fois que l'on veut.
			\newline Voici le code (Disponible dans /SSH/Exec.java) de création d'un tunnel :
			
			\begin{lstlisting}[language=java]
try{
	JSch jsch=new JSch();
	this.session=jsch.getSession("pi", "169.254.14.03", 22);
	UserInfo ui=new MyUserInfo();
  this.session.setUserInfo(ui);
  this.session.connect();
  this.channel = this.session.openChannel("exec");
  ((ChannelExec)this.channel).setCommand(this.Commande);
  this.channel.setInputStream(null);
  ((ChannelExec)this.channel).setErrStream(System.err);
  this.in=this.channel.getInputStream();
  this.channel.connect();
  byte[] tmp=new byte[1024];
  while(true){
		while(this.in.available()>0){
			int i=this.in.read(tmp, 0, 1024);
      if(i<0)break;
      System.out.print(new String(tmp, 0, i));
      this.retour=new String(tmp, 0, i);
    }
    if(channel.isClosed()){
			if(this.in.available()>0) continue; 
			System.out.println("exit-status: "+channel.getExitStatus());
      break;
     }
   }
}
catch(Exception e){
	System.out.println(e);
}
			\end{lstlisting}
			De la ligne 1 à 5, le tunnel est crée et les informations tel que le nom d'utilisateur, le mot de passe, l'adresse IP et le port sont ajouté aux couches correspondante du tunnel, puis ligne 6 la session est lancée.
		\newline A la ligne 7, nous ouvrons un canal d’exécution de commande et ligne 8 nous donnons à ce canal la commande que nous voulons envoyée.
		\newline Les lignes 9,10 et 11 définissent où vont les données entrées, sorties et sorties erreur. Dans notre cas l'entrée ne nous intéresse pas car cela passe par une commande, la sortie normal sera stockée et la sortie erreur renvoyée sur l'afficheur d'erreur du système (la console). La ligne 12 lance la connexion du canal, c'est ici que la commande est envoyée.
		\newline De la ligne 13 à 20 nous permet de récupérer les valeurs retournées par la Raspberry et de les stocker pour ensuite pouvoir les traiter.
		\newline Puis les dernières lignes, permettent de gérer le cas où le canal est coupé et nous renvoyer d'où vient l'erreur (par exceptions).
		\newline \newline Ces tunnels nous permettent d'envoyer des commandes à la Raspberry et de pouvoir récupérer le retour de cette commande. C'est par ce moyen que nous récupérons presque tous. L'exception étant pour la vidéo IP. Abordons ce sujet.
		\subsection{Vidéos}
		Nous avons donc 2 flux vidéos à récupérer depuis une adresse IP. Tout d'abord nous devons introduire quelque chose que nous utilisons partout dans notre code: le multi-Thread. Cela permet de lancer plusieurs actions en même temps, c'est ce qu'il se passe avec la récupération des flux vidéos. Chaque image des flux vidéos est récupérée, traitée puis affichée en temps réel sans interrompre le reste du programme, tout comme l'envoie de chaque commande.
		\newline Pour les flux vidéos, c'est une connexion http qui est effectuée, pour cela la méthode connect est appelée:
		\begin{lstlisting}[language=java]
public void connect()
	{
		try
		{
			URL u = new URL(useMJPGStream?mjpgURL:jpgURL);
			huc = (HttpURLConnection) u.openConnection();
			InputStream is = huc.getInputStream();
			connected = true;
			BufferedInputStream bis = new BufferedInputStream(is);
			dis= new DataInputStream(bis);
			if (!initCompleted) initDisplay();
		}
		catch(IOException e)
		{ //Relance la connexion si pas de connexion en attendant 60 sec
			try
			{
				huc.disconnect();
				Thread.sleep(60);
			}
			catch(InterruptedException ie)
			{
				System.out.println(ie);
			}
		}
		catch(Exception e){;}
	}
			\end{lstlisting}
			De la ligne 5 à 10, la procédure de connexion http est effectuée.
			\newline Après la ligne 12, on gère les exceptions liées à la connexion.
			\newline A la ligne 10, les données récupérées sont stockées dans une variable globale à Caméra.
			\newline Les informations vont être ensuite traité par initDisplay qui est appelée en ligne 11.
			\newline Observons cette méthode :
		\begin{lstlisting}[language=java]
public void initDisplay()
	{ 
		if (useMJPGStream)readMJPGStream();
		else
		{
			readJPG();
			disconnect();
		}
		imageSize = new Dimension((image.getWidth(this)*2), image.getHeight(this)*2);
		setPreferredSize(imageSize);
		parent.validate();
		initCompleted = true;
	}
		\end{lstlisting}
		Le premier If/Else permet de distinguer le cas où le flux serait une vidéo ou juste une photo. Dans notre cas c'est un flux vidéo composé d'image JPG.
		\newline Le reste de la méthode permet de préparer l'affichage des images.
		\newline Nous somme toujours dans la procédure de connexion, la lecture de la première image récupérée est faite. Pour cela la méthode readMJPGStream qui appel readJPG permet de décoder l'image et de la stocker dans la variable image. Voici les 2 méthodes :
		\begin{lstlisting}[language=java]
public void readMJPGStream()
	{
		readLine(4,dis); //enlève les 3 premières lignes
		readJPG();
		readLine(1,dis); //enlève les 2 dernières lignes
	}
	
public void readJPG()
	{
		try{
			JPEGImageDecoder decoder = JPEGCodec.createJPEGDecoder(dis);
			image = decoder.decodeAsBufferedImage();
		}catch(Exception e){
			disconnect();
		}
	}
		\end{lstlisting}
		La procédure de décodage d'une image JPEG est faite par une bibliothèque externe.
		\newpage Après cette procédure de connexion, les 2 méthodes ci dessus sont appelées en boucle et l'affichage mis à jour:
		\begin{lstlisting}[language=java]
public void readStream()
	{
		try{
			if (useMJPGStream){
				while(true){
					readMJPGStream();
					parent.repaint();
				}
			}
    	}catch(Exception e){;}
    }
		\end{lstlisting}
		L'affichage étant gérée par la bibliothèque Swing, c'est la méthode paint() qui affiche l'image et de plus trace une ligne qui en fonction des angles d’Euler renvoyés par la centrale inertielle :
		\begin{lstlisting}[language=java]
public void paint(Graphics g)
	{
		if (image != null)
			image=scale(image, 2);
			g.drawImage(image, 0, 0, this);
			Graphics2D g2 = (Graphics2D) g;
			double alpha = Interface.rotZ* Math.PI/180f;
    	int a = image.getHeight();
    	int b = image.getWidth();
    	double S =(b/2)*(Math.sin(alpha))*(Math.cos((Math.PI/2)-alpha));
    	double T =(b/2)*(Math.sin(alpha))*(Math.sin((Math.PI/2)-alpha));
    	g2.draw(new Line2D.Double(S,(a/2)-T,b-S,(a/2)+T));
	}
		\end{lstlisting}
	L'image est redimensionnée pour le bien de l'affichage et la ligne est tracé avec 2 points calculés par rapport à une rotation avec une origine au centre de l'image.
	\newline \newline Nos 2 flux vidéos sont donc récupérés et peuvent donc être appelés par un JPanel n'importe où.
\newpage
		\subsection{Capteurs et Moteurs}
		\subsubsection{Capteurs}
		Nous avons déjà précédemment préparé la Raspberry pour qu'elle renvoit les informations que l'on veut en fonction d'une commande. Il nous suffit maintenant d'envoyer en temps réel et en boucle infini les commandes (capteur de pression et centrale inertielle) grâce au système de multi-thread.
		\newline Expliquons la méthode pour le capteur de pression. Tout d'abord il faut crée le thread lié à la classe qui sera exécuté en boucle, puis on lance le thread avec la méthode, ce qui donne :
		\begin{lstlisting}[language=java]
Pression ex4 = new Pression();
Thread a4 = new Thread(ex4);
a4.start();
		\end{lstlisting}
		La classe Pression doit être héritière de Runnable pour permettre le lancement en thread.
		\newline Observons dans la classe Pression, la méthode start:
		\begin{lstlisting}[language=java]
Interface.exPression.Commander("python MS5803_14BA.py");
String[] a = Interface.exPression.retour.split("/");
this.Pression=a[0];
this.TemperatureC=a[1];
this.TemperatureF=a[2];
Interface.pre=Pression;
Interface.tempC=TemperatureC;
Interface.tempF=TemperatureF;
Interface.pression.setText(" Pression = "+Interface.pre);
Interface.pression.repaint();
Interface.temperatureC.setText(" TemperatureC = "+Interface.tempC);
Interface.temperatureC.repaint();
Interface.temperatureF.setText(" TemperatureF = "+Interface.tempF);
Interface.temperatureF.repaint();
		\end{lstlisting}
		Nous commençons en ligne 1 par envoyer la commande grâce au tunnel précédemment crée pour le capteur de Pression puis nous récupérons les valeurs sous forme de chaînes de caractères.
		\newline Enfin nous mettons à jour les valeurs globales et l’affichage.
		
		\subsubsection{Moteurs}
		Pour les moteurs, on envoie juste une commande à la Raspberry :
		\begin{lstlisting}[language=java]
Interface.exMoteur.setCommande("echo 0="+m1+" > /dev/servoblaster & echo 1="+m2+" > /dev/servoblaster & echo 2="+m3+" > /dev/servoblaster");
Thread a1 = new Thread(Interface.exMoteur);
a1.start();
while( a1.isAlive()) {}
Interface.m1=this.m1;
Interface.m2=this.m2;
Interface.m3=this.m3;
Interface.moteur1.setText(""+Interface.m1+"    ");
Interface.moteur1.repaint();
Interface.moteur2.setText(""+Interface.m2+"    ");
Interface.moteur2.repaint();
Interface.moteur3.setText(""+Interface.m3+"    ");
Interface.moteur3.repaint();
		\end{lstlisting}
		On oublie pas de mettre à jour au passage l'affichage.
		\newline Ce code est donc exécuté à chaque fois que l'on appuie sur une des touches de directions.
		\newline Nous avons défini les touches suivantes:
		\newline Monter/Descente : Z/S
		\newline Gauche/Droite : Flèche Gauche/Droite
		\newline Monter/Descente : Z/S
		\newline Arrête d'urgence : Barre Espace
		
		\subsection{Affichage 3D}
			\label{subsec:Affichage 3D}
			Nous utilisons JAVA3D pour afficher le modèle qui est extrait de Solidworks.
			\newline Tout d'abord nous devons crée un canvas 3D qui contiendra notre objet 3D et nous l’insérons au milieux d'un JPanel :
		\begin{lstlisting}[language=java]
Canvas3D canvas3D = new Canvas3D(SimpleUniverse.getPreferredConfiguration());
this.add(canvas3D, BorderLayout.CENTER);
		\end{lstlisting}
		Puis nous créons un simple univers qui contient notre canvas3D.
		\newline Nous devons maintenant positionner notre point d'observation pour avoir une vue correcte:
		\begin{lstlisting}[language=java]
OrbitBehavior orbit = new OrbitBehavior(canvas3D, OrbitBehavior.REVERSE_ROTATE);
orbit.setRotXFactor(0);//or any other value
orbit.setRotYFactor(0);
orbit.setTransXFactor(0);
orbit.setTransYFactor(0);
orbit.setSchedulingBounds(new BoundingSphere());
simpleU.getViewingPlatform().setViewPlatformBehavior(orbit);
ViewingPlatform vp = simpleU.getViewingPlatform();
TransformGroup steerTG = vp.getViewPlatformTransform();
Transform3D t3d = new Transform3D();
steerTG.getTransform(t3d);
t3d.lookAt(new Point3d(-1.2,1.2,1.2), new Point3d(0,0,0), new Vector3d(0,1,0));
t3d.invert();
steerTG.setTransform(t3d);
		\end{lstlisting}
		De la ligne 1 à 6, nous définissions un mouvement orbital de la caméra puis pour le moment nous fixons les rotations et les translations (on pourra les débloquer si on le veut)
		\newline Les lignes 9 à 14 permettent de définir la position initiale de notre point d'observation.
		\newline Nous devons ensuite crée ce qu'on appelle une scène, c'est dans cette scène que tous nos objets 3d se trouveront:
		\begin{lstlisting}[language=java]
BranchGroup scene = createSceneGraph(simpleU);
scene.compile();
simpleU.addBranchGraph(scene);
		\end{lstlisting}
		Les 2 ligns suivant compile la scène et rattache notre scène à l'univers.
		\newline \newline Maintenant nous devons crée cette scène 3d qui contiendra notre objet mais aussi la lumière, notre eau fictive et les mouvements possible.
		\newline Tous ce passe dans la méthode createSceneGraph.
		\begin{lstlisting}[language=java]
public BranchGroup createSceneGraph(SimpleUniverse simpleU) 
	{
    BranchGroup parent = new BranchGroup();
    BoundingSphere bounds = new BoundingSphere(new Point3d(), 100);
    Light ambientLight = new AmbientLight(new Color3f(Color.white));
    ambientLight.setInfluencingBounds(bounds);
    parent.addChild(ambientLight);
		
    Light directionalLight = new DirectionalLight(
      new Color3f(Color.white),
      new Vector3f(1, -1, -1));
    directionalLight.setInfluencingBounds(bounds);
    parent.addChild(directionalLight);
		\end{lstlisting}
		La ligne 3 crée un objet parent qui contiendra tous nos objets.
		\newline De la ligne à 4 à 7, on crée une lumière ambiante de couleur blanche
		\newline Puis de la ligne 9 à la ligne 13, une lumière directionnel pour augmenter la luminosité dans la même direction que notre point d'observation.
		\newline Nous ne détaillerons pas ici le code de la création de l'eau, le principe étant qu'on a crée 4 plans positionnés correctement autour du ROV et on lui applique une texture bleu (que l'on peut changer facilement). Et on oublie pas de l'ajouter à l'objet parent.
		\newline Maintenant autorisons les mouvements de la souris pour notre objet :
		\begin{lstlisting}[language=java]
TransformGroup mouseTransform = new TransformGroup();
mouseTransform.setCapability(TransformGroup.ALLOW_TRANSFORM_READ);
mouseTransform.setCapability(TransformGroup.ALLOW_TRANSFORM_WRITE);
mouseTransform.addChild(loadWavefrontObject());
		\end{lstlisting}
		Et en ligne 4 nous ajoutons notre ROV. La méthode loadWavefrontObject() permet de récupérer un objet 3D à partir d'un fichier .obj.
		\newline Pour la fin de cette méthode, les commentaires décrivent les opérations effectuées
		\begin{lstlisting}[language=java]
// Création de l'homethetie (homothetie)
Transform3D homothetie = new Transform3D();
homothetie.setScale(Interface.scale); 
    
// Création de la transformation (translation)
 Transform3D translation = new Transform3D();
translation.setTranslation(new Vector3f(0f, 0f, 0f));
translation.mul(homothetie);
    
// Création de la rotation X(rotation)
Transform3D rotationX = new Transform3D();
rotationX.rotX( Interface.rotX * Math.PI/180f);
rotationX.mul(translation);
    
// Création de la rotation Y(rotation)
Transform3D rotationY = new Transform3D();
rotationY.rotY( Interface.rotY * Math.PI/180f);
rotationY.mul(rotationX);
    
// Création de la rotation Z(rotation)
Transform3D rotationZ = new Transform3D();
rotationZ.rotZ( Interface.rotZ * Math.PI/180f);
rotationZ.mul(rotationY);
    
this.rotationGroup = new TransformGroup(rotationZ);

//Autorisation de modifier les transformations
rotationGroup.setCapability(TransformGroup.ALLOW_TRANSFORM_READ);
rotationGroup.setCapability(TransformGroup.ALLOW_TRANSFORM_WRITE);
    
// Ajout au graphe de la scène
rotationGroup.addChild(mouseTransform);
parent.addChild(rotationGroup);

return parent;
		\end{lstlisting}
		Notre scène renvoie donc tous les objets qu'on a crée précédemment.
		\newline \newline Maintenant nous voulons que notre ROV 3D soit capable de se mouvoir en fonction des angles d’Euler renvoyés et stockés dans notre interface.
		\newline Pour cela on a crée une méthode mouvement:
		\begin{lstlisting}[language=java]
public void mouvement(double rotX, double rotY, double rotZ, Vector3d trans, double scale)
		\end{lstlisting}
		Elle prend donc en argument, les 3 rotations, un vecteur des translations (sur tous les axes) et un paramètre multiplicateur d’échelle.
		\newline Cette méthode modifie la matrice 4*4 contenant la matrice de rotation, translation et de mise à l’échelle.
		\newline Puis effectue les transformations de cette matrice.
		
		\subsection{Cartographie}
			\label{subsec:Cartographie}
			Cette partie n'a pas été beaucoup développé mais un premier système a été crée mais pas intégré dans la dernière version de l'interface.
			\newline Grâce à l'appuie sur une touche, une photo de la camera du dessous est enregistrée dans un dossier. Voici le code qui permet d'enregistrer notre photo en jpg :
			\begin{lstlisting}[language=java]
BufferedImage img = new BufferedImage(axPanel.getWidth(), axPanel.getHeight(), BufferedImage.TYPE_INT_RGB);
axPanel.print(img.getGraphics());
try {
	ImageIO.write(img, "jpg", new File(nomPhoto+".jpg"));
}
catch (IOException e5) {
	e5.printStackTrace();
}
		\end{lstlisting}
			Le système n'est pas fini mais dans l'absolu chaque photo serai enregistrée avec un nom différent avec les données de localisation dans les méta-données de la photo.
			\newline Ensuite il y a un autre bouton (non affiché sur la dernière interface) qui ouvre une autre fenêtre avec toutes nos photos positionnées, en fonction des coordonnées GPS, sur une carte.
			\newline On peut cliquer sur chaque photo pour les agrandir dans une nouvelle fenêtre.
			\newline Tous les codes se trouvent dans le sous-dossier /Carto.
			
			\newpage	
			
\chapter{Structure}

	L'objectif suivant, et non des moindres dans la construction d'un véhicule sous-marin, était l'établissement de la structure. Comme on peut le voir dans le cahier des charges, la structure a été pensée dans 6 optiques différentes : étanchéité, transportabilité, durabilité, aqua-dynamisme, esthétisme et personnalisation. 
				
				\section{Design}
				
				Tout d'abord, il fallait donner un premier aspect à notre R.O.V. pour en suite le modifier après différents tests pour mieux correspondre aux 6 optiques explicitées au début. Pour obtenir des idées sur différentes architectures et aussi nous faire gagner du temps sur la conception du design, on a étudié plusieurs R.O.V. du marchés. Voici les 3 R.O.V qui ont eu la plus grosse influence sur notre design:
					
					\begin{figure}[!h]
						\centering
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/produit-aquarov.jpg}
								\caption{Aquarov de Rov developpement}
							\end{subfigure}
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/SeaBotix_LBV_300-1.jpg}
								\caption{SeaBotix d'Advanced Marine}
							\end{subfigure}
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/openrov-trident-rov-2.jpg}
								\caption{Trident d'Open ROV}
							\end{subfigure}
					\end{figure}\newpage
					
					Avec le design de ces drones en tête, on a alors réalisé le notre qui se veut plus épuré dans la même lignée que le Trident. En effet cet aspect se destine mieux à un marché dit 'grand publique'. Très vite, après les premiers croquis, nous sommes passé à une conception sous SolidWorks du R.O.V.. Voici donc son aspect final sous Solidworks ainsi qu'un rendu 3D : 
					
					\begin{figure}[!h]
						\centering
							\begin{subfigure}[b]{0.5\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture1.png}
							\end{subfigure}
							\begin{subfigure}[b]{0.5\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture2.png}
							\end{subfigure}
							\caption{Modélisation du R.O.V. Nautilus sous Solidworks}
					\end{figure}
					
					\begin{figure}[!h]
						\centering
							\begin{subfigure}[b]{0.4\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture3.png}
							\end{subfigure}
							\begin{subfigure}[b]{0.4\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture4.png}
							\end{subfigure}
							\caption{rendu 3D du R.O.V. Nautilus sous Solidworks}
					\end{figure}
					
					Comme on peut l'observer le R.O.V. va se composer de 3 grandes parties : un squelette interne, un tube transparent ainsi qu'une coque. Cela va faciliter l'étanchéification du R.O.V mais aussi la modification ou le remplacement d'une partie sans toucher aux autres. On colle alors parfaitement aux sections esthétisme et personnalisation. Niveau dimensionnement,le R.O.V. a un encombrement total de 300*200*150 mm. 
						\newline
						\newline
					
				\subsection{Squelette interne}
				
				\begin{figure}[!h]
					\begin{center}
						\includegraphics[scale=0.3]{Photos/Capture5.png}
						\caption{squelette interne}
					\end{center}
				\end{figure}
				
				Le squelette interne du R.O.V. joue, comme son nom l'indique, le rôle d'une structure de soutient et de rigidification du Nautilus. C'est donc la partie du R.O.V. la plus résistante à la déformation. L'ensemble des autres parties, comme la coque,les câbles, ainsi que les trois moteurs brushless viennent se fixer dessus bénéficient ainsi de cette solidité. De plus comme l'eau va circuler énormément dans cette zone, le squelette interne a été conçu pour opposer très peu de résistance au passage de l'eau avec de nombreux trous et même concentrer et diriger les flux aux niveaux des moteurs. \newpage
					
					
				\subsection{Tube}	
				
				\begin{figure}[!h]
					\begin{center}
						\includegraphics[scale=0.3]{Photos/Capture6.png}
						\caption{Tube}
					\end{center}
				\end{figure}
				
			Le tube est la partie étanche du Nautilus. En effet, ce tube regroupera l'ensemble de l'électronique. Celui-ci est entièrement transparant pour d'une part permettre de filmer ainsi que de photographier à l'aide de nos deux caméras et d'autre part de permettre à l'utilisateur un contrôle visuel de l'électronique et de l'étanchéité.  
			
				\subsection{Coque}	
				
				\begin{figure}[!h]
					\begin{center}
						\includegraphics[scale=0.3]{Photos/Capture7.png}
						\caption{Coque}
					\end{center}
				\end{figure}
				
			La coque, quand à elle, va apporter le profil nécessaire à un bon aqua-dynamisme ainsi qu'une protection à l'environnement. Elle est aussi au coeur de la problématique de personnalisation car en plus de pouvoir avoir une forme ou une couleur différente, elle peut aussi accueillir des modules supplémentaires par exemple sur les bras à l'avant de sa coque.
			
			\section{Matériaux, méthode de construction}
			
			Une fois le design établit, nous somme passé à la réalisation. Pour un premier prototypage rapide, nous avons choisi l'impression 3D de type ' fused filament fabrication'. Ainsi la coque a été imprimée en PLA et le squelette en ABS, tout deux avec un support en PVA qui est un plastique qui se dissous dans l'eau.
			
					\begin{figure}[!h]
						\centering
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture13.jpg}
							\end{subfigure}
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture14.jpg}
							\end{subfigure}
							\caption{impressions 3D du Nautilus}
					\end{figure}
				\begin{figure}[!h]
						\centering
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture15.jpg}
							\end{subfigure}
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture16.jpg}
							\end{subfigure}
							\caption{impressions 3D du Nautilus}
					\end{figure}
					
					Cependant pour de prochaines impressions de la coque, il sera nécessaire de revoir le positionnement de celle-ci dans la zone d'impression. En effet, les efforts qui s'exercent sur la coque coïncident avec l'agencement des couches de plastique. Ceci explique l'apparition de fissure sur la coque.
					
					
					\newpage
				
		Le tube est réalisé à l'aide d'un tube en acrylique dont une extrémité est un bouchon en acrylique scellé à la résine Epoxy et l'autre est aussi un bouchon avec un joint torique qui permet d'ouvrir le tube.
		
					\begin{figure}[!h]
						\centering
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture9.jpeg}
							\end{subfigure}
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture8.jpeg}
							\end{subfigure}
							\caption{réalisation du tube}
					\end{figure}
					
		Pour que l'ensemble des câbles rentrent dans le tube, un petit accès a été réalisé puis scellé à la résine Epoxy.
		
							\begin{figure}[!h]
						\centering
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture10.jpeg}
							\end{subfigure}
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture11.jpeg}
							\end{subfigure}
							\caption{accès des câbles et coulage de la résine }
					\end{figure}
			
			\section{Simulations poids et aqua-dynamisme}
					Une fois la structure réalisée avec Solidworks, on a attribué les matériaux ou des densités ,quand le matériau n'était pas disponible, aux différents composant.\newline
				Pour un déplacement correct dans l'eau sans modification de l'assiette il faut que le centre d'inertie (en prenant en compte la poussée d’Archimède) soit confondu avec les axes des moteurs.On a donc rajouté des poids en plomb sur le drone en modifiant leurs poids jusqu'à obtenir la positions du centre d'inertie voulue : 
					\begin{figure}[!h]
						\centering
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture20.png}
							\end{subfigure}
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture21.png}
							\end{subfigure}
							\caption{répartition du poids}
					\end{figure}\newline
					
				Avec une assiette correcte, on peut s'intéresser à l'aqua-dynamisme du ROV. En effet à l'aide du module flow-simulation de Solidworks, on place le Nautilus dans un cube de fluide s'écoulant à 2m/s (la vitesse maximale du ROV) et on regarde le comportement de certaines lignes de courants :
									
					\begin{figure}[!h]
					
						\centering
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture22.png}
							\end{subfigure}
							\begin{subfigure}[b]{0.3\textwidth}
								\includegraphics[width=\textwidth]{Photos/Capture23.png}
							\end{subfigure}
							\caption{test d'aqua-dynamisme}
							
					\end{figure}
					
					
				Comme on peut le voir, le fluide qui rencontre l'avant du ROV suit la paroi en accélérant à une vitesse semblable tout autour du Nautilus. Cet écoulement est bien caractéristique d'une bonne pénétration du ROV dans le fluide.\newpage
				
				\section{Test en eau}
				
				\begin{figure}[!h]
					\begin{center}
						\includegraphics[scale=0.1]{Photos/Capture24.jpeg}
						\caption{ROV entièrement monté}
					\end{center}
				\end{figure}
				Une fois la structure entièrement réalisée et testée en simulation, nous avons réalisé les tests en eau. Cependant durant ces tests, nous nous sommes aperçu que le ROV n'était pas parfaitement étanche. En effet au bout d'une dizaine de minutes nous avons pu observer de l'humidité dans le tube. Bien que le reste de la structure se comporte parfaitement bien il faut revoir l'étanchéité du ROV.
			
\chapter{Conclusion}

\bibliographystyle{unsrt} % Le style est mis entre accolades.

\bibliography{bibliographie} % mon fichier de base de données s'appelle bibli.bib

\listoffigures

\end{document}